{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('babyai': conda)"
  },
  "interpreter": {
   "hash": "6e0be762d0aa71c13b0877707367a590eb61c60607cb738dbbfe2697b6e544bd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import gym\n",
    "from babyai.levels.levelgen import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "register_levels('iclr19_levels', globals())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "env = gym.make('BabyAI-GoToImpUnlock-v0')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "observation_space = env.observation_space\n",
    "action_space = env.action_space"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import copy\n",
    "import gym\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import itertools\n",
    "import torch\n",
    "from babyai.evaluate import batch_evaluate\n",
    "import babyai.utils as utils\n",
    "from babyai.rl import DictList\n",
    "from babyai.model import ACModel\n",
    "import multiprocessing\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy \n",
    "import tqdm\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "d_path = \"/data/graceduansu/demos/BabyAI-GoToImpUnlock-v0\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "demos_path = utils.get_demos_path(d_path, None, None, valid=False)\n",
    "train_demos = utils.load_demos(demos_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "rand_inds = np.random.choice(len(train_demos), size=6400)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "some_demos = [train_demos[i] for i in rand_inds]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "len(train_demos)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "demo_list = utils.demos.transform_demos(some_demos)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from gym_minigrid.minigrid import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### for each concept: sample random demos from batch, create smaller flat batches, save as one pkl"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cuda6 = torch.device('cuda:6')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### concept 1: search for key for locked door\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\"\"\"\n",
    "for demos that have unlock action:\n",
    "    _color_ = get door color\n",
    "    label timesteps [] to [pick up _color_ key]\n",
    "\"\"\"\n",
    "\n",
    "# save inds and concept inds, generate all memories, then slice to concept inds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nfor demos that have unlock action:\\n    _color_ = get door color\\n    label timesteps [] to [pick up _color_ key]\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "for i in range(128):\n",
    "\n",
    "    batch = []\n",
    "    concept_inds = []\n",
    "\n",
    "    # filter for 1280 demos that have unlock action\n",
    "    count = 0\n",
    "    while count < 1280:\n",
    "        unlock_idx = None\n",
    "        pickup_idx = None\n",
    "\n",
    "        while unlock_idx is None or pickup_idx is None:\n",
    "            rand_idx = 0\n",
    "            dem = some_demos[rand_idx]\n",
    "            dem_transformed = demo_list[rand_idx]\n",
    "\n",
    "            # if demo has Toggle (unlock) action\n",
    "            if env.actions.toggle in dem[3] and env.actions.pickup in dem[3]:\n",
    "                # unlock_idx = dem[3].index(env.actions.toggle)\n",
    "                # check if object is door\n",
    "                # print(dem_transformed[unlock_idx][0]['image'][5][3][0])\n",
    "                # while dem_transformed[unlock_idx][0]['image'][5][3][0] != 4:\n",
    "                #     temp = unlock_idx\n",
    "                #     print(temp)\n",
    "                #     unlock_idx = dem[3].index(env.actions.toggle, temp)\n",
    "                color = None\n",
    "                for t in range(len(dem_transformed)):\n",
    "                    isdoor = (dem_transformed[t][0]['image'][5][3][0] == 4)\n",
    "                    istoggle = (dem[3][t] == env.actions.toggle)\n",
    "                    if isdoor and istoggle:\n",
    "                        unlock_idx = t\n",
    "                        color = dem_transformed[unlock_idx][0]['image'][5][3][1]\n",
    "                    \n",
    "                    if color:\n",
    "                        iskey = (dem_transformed[t][0]['image'][5][3][0] == 5)\n",
    "                        iscolor = (dem_transformed[t][0]['image'][5][3][1] == c)\n",
    "                        if iskey and istoggle:\n",
    "                            pickup_idx = t\n",
    "                            \n",
    "\n",
    "\n",
    "        print('exit')\n",
    "        # get door color\n",
    "        c = dem_transformed[unlock_idx][0]['image'][5][3][1]\n",
    "        # get pick up _c_ key idx\n",
    "        pickup_idx = dem[3].index(env.actions.pickup)\n",
    "        # check if object is key\n",
    "        assert dem_transformed[pickup_idx][0]['image'][5][3][0] == 5\n",
    "        assert dem_transformed[pickup_idx][0]['image'][5][3][1] == c\n",
    "\n",
    "        # (start, end) idx\n",
    "        batch.append(dem_transformed)\n",
    "        concept_inds.append((pickup_idx, unlock_idx))\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    batch.sort(key=len, reverse=True)\n",
    "    # Constructing flat batch and indices pointing to start of each demonstration\n",
    "    flat_batch = []\n",
    "    inds = [0]\n",
    "    flat_concept_inds = [(0,0)]\n",
    "\n",
    "    for demo in batch:\n",
    "        flat_batch += demo\n",
    "        inds.append(inds[-1] + len(demo))\n",
    "        flat_concept_inds.append((inds[-1] + pickup_idx, inds[-1] + unlock_idx))\n",
    "\n",
    "    flat_batch = np.array(flat_batch)\n",
    "    inds = inds[:-1]\n",
    "    flat_concept_inds = flat_concept_inds[:-1]\n",
    "    num_frames = len(flat_batch)\n",
    "\n",
    "    assert len(flat_concept_inds) == len(inds) \n",
    "\n",
    "    mask = np.ones([len(flat_batch)], dtype=np.float64)\n",
    "    mask[inds] = 0\n",
    "    mask = torch.tensor(mask, device=cuda6, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    # get batch with only concepts\n",
    "    flat_concept_batch = []\n",
    "    concept_inds = [0]\n",
    "    for pair in flat_concept_inds:\n",
    "        concept_data = flat_batch[pair[0]:pair[1]]\n",
    "        flat_concept_batch += concept_data\n",
    "        concept_inds.append(concept_inds[-1] + (pair[1] - pair[0]))\n",
    "\n",
    "    concept_mask = np.ones([len(flat_concept_batch)], dtype=np.float64)\n",
    "    concept_mask[concept_inds] = 0\n",
    "    concept_mask = torch.tensor(concept_mask, device=cuda6, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    # Observations, true action, values and done for each of the stored demostration\n",
    "    obss, action_true, done = flat_batch[:, 0], flat_batch[:, 1], flat_batch[:, 2]\n",
    "\n",
    "    episode_ids = np.zeros(len(flat_batch))\n",
    "    inds_copy = inds.copy()\n",
    "\n",
    "    # Loop terminates when every observation in the flat_batch has been handled\n",
    "    while True:\n",
    "        # taking observations and done located at inds\n",
    "        done_step = done[inds]\n",
    "        episode_ids[inds] = range(len(inds))\n",
    "\n",
    "        # Updating inds, by removing those indices corresponding to which the demonstrations have finished\n",
    "        inds = inds[:len(inds) - sum(done_step)]\n",
    "        if len(inds) == 0:\n",
    "            break\n",
    "\n",
    "        # Incrementing the remaining indices\n",
    "        inds = [index + 1 for index in inds]\n",
    "\n",
    "    # make concept_episode_ids\n",
    "    obss, action_true, done = flat_concept_batch[:, 0], flat_concept_batch[:, 1], flat_concept_batch[:, 2]\n",
    "\n",
    "    concept_episode_ids = np.zeros(len(flat_concept_batch))\n",
    "    concept_inds_copy = concept_inds.copy()\n",
    "\n",
    "    # Loop terminates when every observation in the flat_batch has been handled\n",
    "    while True:\n",
    "        # taking observations and done located at inds\n",
    "        done_step = done[concept_inds]\n",
    "        concept_episode_ids[concept_inds] = range(len(concept_inds))\n",
    "\n",
    "        # Updating inds, by removing those indices corresponding to which the demonstrations have finished\n",
    "        concept_inds = concept_inds[:len(concept_inds) - sum(done_step)]\n",
    "        if len(concept_inds) == 0:\n",
    "            break\n",
    "\n",
    "        # Incrementing the remaining indices\n",
    "        concept_inds = [index + 1 for index in concept_inds]\n",
    "\n",
    "    # {flat_batch, mask, episode_ids, inds_copy, \n",
    "    #   flat_batch_concept_inds, \n",
    "    #   concept_mask, concept_episode_ids, concept_inds} <-- inds after batch only has concepts\n",
    "    batch_dict_list = {'flat_batch': flat_batch,\n",
    "                        'mask': mask,\n",
    "                        'episode_ids': episode_ids,\n",
    "                        'inds': inds_copy,\n",
    "                        'flat_batch_concept_inds': flat_concept_inds,\n",
    "                        'concept_mask': concept_mask,\n",
    "                        'concept_episode_ids': concept_episode_ids,\n",
    "                        'concept_inds': concept_inds}\n",
    "\n",
    "    path = '/data/graceduansu/concepts/1_search_for_key/batch' + str(i)\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(batch_dict_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-94665b75b1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0misdoor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdem_transformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mistoggle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoggle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misdoor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mistoggle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### concept 2: take key to locked door\n",
    "### concept 3: search for target object (default subgoal)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### testing stuff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "flat_batch = np.arange(200)\n",
    "# batch_size = 50, \n",
    "demo_length = 40\n",
    "memory_size = 25\n",
    "num_frames = len(flat_batch)\n",
    "recurrence = 5\n",
    "\n",
    "inds = np.arange(0, len(flat_batch), demo_length)\n",
    "\n",
    "\n",
    "memories = torch.zeros([len(flat_batch), memory_size])\n",
    "episode_ids = np.zeros(len(flat_batch))\n",
    "memory = torch.zeros([50, memory_size])\n",
    "\n",
    "mask = np.ones([len(flat_batch)], dtype=np.float64)\n",
    "mask[inds] = 0\n",
    "mask = torch.tensor(mask, dtype=torch.float).unsqueeze(1)\n",
    "# print(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "while True:\n",
    "    # taking observations and done located at inds\n",
    "    done_step = np.arange(0, len(flat_batch), demo_length)[1:]\n",
    "    new_memory = np.arange(1000, 1025)\n",
    "    new_memory = torch.tensor(new_memory)\n",
    "    memories[inds, :] = memory[:len(inds), :]\n",
    "    memory[:len(inds), :] = new_memory\n",
    "    episode_ids[inds] = range(len(inds))\n",
    "\n",
    "    # Updating inds, by removing those indices corresponding to which the demonstrations have finished\n",
    "    inds = inds[:len(inds) - sum(done_step)]\n",
    "    if len(inds) == 0:\n",
    "        break\n",
    "\n",
    "    # Incrementing the remaining indices\n",
    "    inds = [index + 1 for index in inds]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(episode_ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "indexes = np.arange(0, num_frames, recurrence)\n",
    "mask_step = mask[indexes]\n",
    "print(len(mask_step))\n",
    "print(len(mask))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40\n",
      "200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "len(indexes)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "mask.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([200, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "mask_step.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([40, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print(memory)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1000., 1001., 1002.,  ..., 1022., 1023., 1024.],\n",
      "        [1000., 1001., 1002.,  ..., 1022., 1023., 1024.],\n",
      "        [1000., 1001., 1002.,  ..., 1022., 1023., 1024.],\n",
      "        ...,\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.],\n",
      "        [   0.,    0.,    0.,  ...,    0.,    0.,    0.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "memory.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([50, 25])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print(memories.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([200, 25])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "memory = memories[indexes]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(memory.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([40, 25])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "memory = torch.rand((40,25))\n",
    "# print(memory)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "res = memory * mask_step\n",
    "print(res.size())\n",
    "# print(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([40, 25])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "indexes += 1\n",
    "print(indexes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  1   6  11  16  21  26  31  36  41  46  51  56  61  66  71  76  81  86\n",
      "  91  96 101 106 111 116 121 126 131 136 141 146 151 156 161 166 171 176\n",
      " 181 186 191 196]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "mask_step = mask[indexes]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}